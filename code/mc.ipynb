{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/zzada/fconv\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import zscore, pearsonr\n",
    "from util import subject\n",
    "from util import plot\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from constants import *\n",
    "from tqdm import tqdm\n",
    "from util.path import Path\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "from himalaya.scoring import correlation_score\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "# resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1e9\n",
    "\n",
    "# from util.atlas import get_glasser, parcellate_voxels\n",
    "# pmask, plabels = get_glasser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"model-gpt2-medium_layer-0.75\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58 [00:07<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for subA in tqdm(SUBS_STRANGERS):\n",
    "    subB = subject.get_partner(subA)\n",
    "\n",
    "    # load encoding model\n",
    "    encpath = Path(root=\"encoding\", sub=f\"{subA:03d}\", datatype=modelname, ext=\".pkl\")\n",
    "    with open(encpath, \"rb\") as f:\n",
    "        dsA = pickle.load(f)\n",
    "\n",
    "    encpath = Path(root=\"encoding\", sub=f\"{subB:03d}\", datatype=modelname, ext=\".pkl\")\n",
    "    with open(encpath, \"rb\") as f:\n",
    "        dsB = pickle.load(f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/zzada/conda-envs/fconv/lib/python3.11/site-packages/numpy/core/_methods.py:118: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "/scratch/gpfs/zzada/conda-envs/fconv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1024, 74947), (1024, 74947))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpA = np.stack(dsA['cv_weights_prod']).mean(0)\n",
    "wcB = np.nanmean(np.nan_to_num(np.stack(dsB['cv_weights_comp'])), axis=0)\n",
    "wpA.shape, wcB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpAd = torch.tensor(wpA, device='cuda')\n",
    "wcBd = torch.tensor(wcB, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.93 GiB (GPU 0; 15.89 GiB total capacity; 1.73 GiB already allocated; 13.80 GiB free; 1.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/scratch/gpfs/zzada/fconv/code/mc.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdella-vis2/scratch/gpfs/zzada/fconv/code/mc.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m D \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcdist(wpAd\u001b[39m.\u001b[39;49mT[\u001b[39mNone\u001b[39;49;00m], wcBd\u001b[39m.\u001b[39;49mT[\u001b[39mNone\u001b[39;49;00m])\n",
      "File \u001b[0;32m/scratch/gpfs/zzada/conda-envs/fconv/lib/python3.11/site-packages/torch/functional.py:1222\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1220\u001b[0m         cdist, (x1, x2), x1, x2, p\u001b[39m=\u001b[39mp, compute_mode\u001b[39m=\u001b[39mcompute_mode)\n\u001b[1;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m compute_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39muse_mm_for_euclid_dist_if_necessary\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mcdist(x1, x2, p, \u001b[39mNone\u001b[39;49;00m)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[39melif\u001b[39;00m compute_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39muse_mm_for_euclid_dist\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1224\u001b[0m     \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mcdist(x1, x2, p, \u001b[39m1\u001b[39m)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.93 GiB (GPU 0; 15.89 GiB total capacity; 1.73 GiB already allocated; 13.80 GiB free; 1.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "D = torch.cdist(wpAd.T[None], wcBd.T[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/50865287\n",
    "# https://stackoverflow.com/a/64477333\n",
    "# pytorch cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = cdist(wpA.T, wcB.T, metric='euclidean', )\n",
    "D.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fconv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
